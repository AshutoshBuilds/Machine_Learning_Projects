{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font style = \"color:rgb(139,0,0)\">Neural Networks : Project 1 - Part 3</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â€¢ CONTEXT: Develop a clickable GUI [desk application or web service application] which can automate Part I & II of this\n",
    "project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-20T04:47:14.672537Z",
     "start_time": "2021-05-20T04:46:38.834885Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Creating application window\n",
    "win = tk.Tk()\n",
    "#  giving title to the window\n",
    "win.title('Neural-Networks-GUI') \n",
    "\n",
    "# A:- Importing name of the dataframe\n",
    "\n",
    "Name=ttk.Label(win,text=\"    Step 1: File Name\")\n",
    "Name.grid(row=0,column=0,sticky=tk.W)\n",
    "\n",
    "Name_var=tk.StringVar()\n",
    "Name_entrybox=ttk.Entry(win,width=16,textvariable=Name_var)\n",
    "Name_entrybox.grid(row=0,column=1)\n",
    "\n",
    "def Import_Data():\n",
    "    global DB\n",
    "    DF_Name=Name_var.get()\n",
    "    DB_extension=re.findall(\"\\..*\", DF_Name) \n",
    "    if DB_extension==['.xlsx']:\n",
    "        DB=pd.read_excel(DF_Name)\n",
    "    elif DB_extension==['.csv']:\n",
    "        DB=pd.read_csv(DF_Name)\n",
    "# creating blank empty window to show the confirmation\n",
    "    confirm=\"Done\"\n",
    "    Confirm_entrybox=ttk.Entry(win,width=16)\n",
    "    Confirm_entrybox.grid(row=0,column=3)\n",
    "    Confirm_entrybox.insert(1,str(confirm))   \n",
    "\n",
    "Import_Data_Button=ttk.Button(win,text=\"Import Data\",command=Import_Data)\n",
    "Import_Data_Button.grid(row=0,column=2)\n",
    "\n",
    "\n",
    "# B:- creating name of the target dataframe \n",
    "\n",
    "Target=ttk.Label(win,text=\"    Step 2: Target Colummn\")\n",
    "Target.grid(row=1,column=0,sticky=tk.W)\n",
    "\n",
    "Target_var=tk.StringVar()\n",
    "Target_entrybox=ttk.Entry(win,width=16,textvariable=Target_var)\n",
    "Target_entrybox.grid(row=1,column=1)\n",
    "\n",
    "# creating function for showing status\n",
    "def Target_Data():\n",
    "    global DB,X,y, Target_Name, X_train, X_test, y_train, y_test\n",
    "    Target_Name=Target_var.get()\n",
    "    \n",
    "    Column_name=DB.columns\n",
    "    Column_name\n",
    "    found=0\n",
    "\n",
    "    for i in range(len(Column_name)):\n",
    "        if Column_name[i]==Target_Name:\n",
    "            confirm=\"Found\"\n",
    "        else:\n",
    "            confirm=\"Not Found\"\n",
    "    \n",
    "    Confirm_entrybox=ttk.Entry(win,width=16)\n",
    "    Confirm_entrybox.grid(row=1,column=3)\n",
    "    Confirm_entrybox.insert(1,str(confirm))\n",
    "\n",
    "\n",
    "Target_Button=ttk.Button(win,text=\"Import Target\",command=Target_Data)\n",
    "Target_Button.grid(row=1,column=2)\n",
    "\n",
    "\n",
    "# C:- building regression model \n",
    "\n",
    "Modelling=ttk.Label(win,text=\"    Step 3: Neural Network Regressor\")\n",
    "Modelling.grid(row=2,column=0,sticky=tk.W)\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential # Forward prop\n",
    "from keras.layers import Dense, Activation, LeakyReLU\n",
    "from keras import optimizers\n",
    "\n",
    "Regression=ttk.Label(win,text=\"Regression\")\n",
    "Regression.grid(row=3,column=0,sticky=tk.E)\n",
    "\n",
    "\n",
    "def NNReg():\n",
    "    global DB,X,Y,NN_model_Regressor\n",
    "    \n",
    "    # Regression\n",
    "    X=DB.drop('Signal_Strength',axis=1)     \n",
    "    Y=DB['Signal_Strength']               \n",
    "\n",
    "    X_Train,X_Test,Y_Train,Y_Test=train_test_split(X, Y, train_size=0.7, random_state=12)\n",
    "    \n",
    "    X_Train_S = StandardScaler().fit_transform(X_Train)   \n",
    "    X_Test_S = StandardScaler().fit_transform(X_Test)     \n",
    "    \n",
    "    # Model \n",
    "    NN_model_Regressor = Sequential()\n",
    "    NN_model_Regressor.add(Dense(128, kernel_initializer='normal',input_dim = X_Train.shape[1], activation='relu'))\n",
    "    NN_model_Regressor.add(Dense(64, kernel_initializer='normal',activation='relu'))  # sigmoid, tanh\n",
    "    NN_model_Regressor.add(Dense(32, kernel_initializer='normal'))\n",
    "    NN_model_Regressor.add(LeakyReLU(alpha=0.1))\n",
    "    NN_model_Regressor.add(Dense(16, kernel_initializer='normal'))\n",
    "    NN_model_Regressor.add(LeakyReLU(alpha=0.1))\n",
    "    NN_model_Regressor.add(Dense(1, kernel_initializer='normal'))  \n",
    "    NN_model_Regressor.add(LeakyReLU(alpha=0.1))\n",
    "    # Compile the network :\n",
    "    NN_model_Regressor.compile(loss='mean_absolute_error', optimizer='adam', metrics=['accuracy'])\n",
    "    NN_model_Regressor.summary()\n",
    "    EPOCH=400\n",
    "    Network_Regressor=NN_model_Regressor.fit(X_Train_S, Y_Train, validation_data=(X_Test_S,Y_Test), epochs=EPOCH, batch_size=200)\n",
    "    \n",
    "    \n",
    "    Confirm_entrybox=ttk.Entry(win,width=16)\n",
    "    Confirm_entrybox.grid(row=3,column=2)\n",
    "    Confirm_entrybox.insert(1,str(\"Network Trained\"))\n",
    "\n",
    "Reg_Button=ttk.Button(win,text=\"Train\",command=NNReg)\n",
    "Reg_Button.grid(row=3,column=1)\n",
    "\n",
    "from keras.models import model_from_json\n",
    "import numpy\n",
    "import os\n",
    "\n",
    "Pickle=ttk.Label(win,text=\"Pickle\")\n",
    "Pickle.grid(row=4,column=0,sticky=tk.E)\n",
    "\n",
    "def Pickle():\n",
    "    # Pickling the model to JSON\n",
    "    Regressor_model_json = NN_model_Regressor.to_json()\n",
    "    with open(\"Regressor_model.json\", \"w\") as json_file:\n",
    "        json_file.write(Regressor_model_json)\n",
    "    # Pickling weights to HDF5\n",
    "    NN_model_Regressor.save_weights(\"Regressor_model.h5\")\n",
    "    \n",
    "    Confirm_entrybox=ttk.Entry(win,width=16)\n",
    "    Confirm_entrybox.grid(row=4,column=2)\n",
    "    Confirm_entrybox.insert(1,str(\"Saved model to disk\"))\n",
    "\n",
    "Pickle_Button=ttk.Button(win,text=\"Run\",command=Pickle)\n",
    "Pickle_Button.grid(row=4,column=1)\n",
    "\n",
    "\n",
    "# D:- Classifier \n",
    "\n",
    "Modelling=ttk.Label(win,text=\"    Step 4: Neural Network Classifier\")\n",
    "Modelling.grid(row=5,column=0,sticky=tk.W)\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential # Forward prop\n",
    "from keras.layers import Dense, Activation, LeakyReLU\n",
    "from keras import optimizers\n",
    "from keras.models import model_from_json\n",
    "import numpy\n",
    "import os\n",
    "\n",
    "Classifier=ttk.Label(win,text=\"Classifier\")\n",
    "Classifier.grid(row=6,column=0,sticky=tk.E)\n",
    "\n",
    "def NNClassi():\n",
    "    global DB,X,Y,NN_model_Classifier\n",
    "    \n",
    "    # Regression\n",
    "    X=DB.drop('Signal_Strength',axis=1)   \n",
    "    Y=DB['Signal_Strength']              \n",
    "\n",
    "    X_Train,X_Test,Y_Train,Y_Test=train_test_split(X, Y, train_size=0.7, random_state=12)\n",
    "\n",
    "    X_Train,X_Test,Y_Train,Y_Test=train_test_split(X, Y, train_size=0.7, random_state=12)\n",
    "    \n",
    "    X_Train_S = StandardScaler().fit_transform(X_Train)  \n",
    "    X_Test_S = StandardScaler().fit_transform(X_Test)     \n",
    "    \n",
    "    Y_Train = to_categorical(Y_Train)\n",
    "    Y_Test = to_categorical(Y_Test)\n",
    "    \n",
    "    NN_model_Classifier = Sequential()\n",
    "\n",
    "    # The Input Layer :\n",
    "    NN_model_Classifier.add(Dense(128, kernel_initializer='normal',input_dim = X_Train.shape[1], activation='relu'))\n",
    "\n",
    "    # The Hidden Layers :\n",
    "    NN_model_Classifier.add(Dense(64, kernel_initializer='normal',activation='relu'))  # sigmoid, tanh\n",
    "\n",
    "    NN_model_Classifier.add(Dense(32, kernel_initializer='normal'))\n",
    "    NN_model_Classifier.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "    NN_model_Classifier.add(Dense(16, kernel_initializer='normal'))\n",
    "    NN_model_Classifier.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "\n",
    "    # The Output Layer :\n",
    "    NN_model_Classifier.add(Dense(9, kernel_initializer='normal',activation='softmax'))  # except softmax\n",
    "\n",
    "    # Compiling the network :\n",
    "    NN_model_Classifier.compile(loss='mean_absolute_error', optimizer='adam', metrics=['accuracy'])\n",
    "    NN_model_Classifier.summary()\n",
    "    EPOCH=400\n",
    "    Network_Classifier=NN_model_Classifier.fit(X_Train_S, Y_Train, validation_data=(X_Test_S,Y_Test), epochs=EPOCH, batch_size=200)\n",
    "    \n",
    "    \n",
    "    Confirm_entrybox=ttk.Entry(win,width=16)\n",
    "    Confirm_entrybox.grid(row=6,column=2)\n",
    "    Confirm_entrybox.insert(1,str(\"Network Trained\"))\n",
    "\n",
    "Cla_Button=ttk.Button(win,text=\"Train\",command=NNClassi)\n",
    "Cla_Button.grid(row=6,column=1)\n",
    "\n",
    "Pickle=ttk.Label(win,text=\"Pickle\")\n",
    "Pickle.grid(row=4,column=0,sticky=tk.E)\n",
    "\n",
    "def Pickle2():\n",
    "    # Pickling the model to JSON\n",
    "    Classifier_model_json = NN_model_Classifier.to_json()\n",
    "    with open(\"Classifier_model.json\", \"w\") as json_file:\n",
    "        json_file.write(Classifier_model_json)\n",
    "    # Pickling the weights to HDF5\n",
    "    NN_model_Classifier.save_weights(\"Classifier_model.h5\")\n",
    "    \n",
    "    Confirm_entrybox=ttk.Entry(win,width=16)\n",
    "    Confirm_entrybox.grid(row=7,column=2)\n",
    "    Confirm_entrybox.insert(1,str(\"Saved model to disk\"))\n",
    "\n",
    "Pickle_Button2=ttk.Button(win,text=\"Run\",command=Pickle2)\n",
    "Pickle_Button2.grid(row=7,column=1)\n",
    "\n",
    "win.mainloop()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
